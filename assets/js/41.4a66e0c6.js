(window.webpackJsonp=window.webpackJsonp||[]).push([[41],{364:function(e,t,a){e.exports=a.p+"assets/img/rulegraph.b89deed5.png"},387:function(e,t,a){"use strict";a.r(t);var r=a(15),o=Object(r.a)({},(function(){var e=this,t=e._self._c;return t("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[t("h1",{attrs:{id:"workflow"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#workflow"}},[e._v("#")]),e._v(" Workflow")]),e._v(" "),t("p",[e._v("The "),t("a",{attrs:{href:"https://snakemake.readthedocs.io/en/stable/executing/cli.html",target:"_blank",rel:"noopener noreferrer"}},[e._v("rulegraph"),t("OutboundLink")],1),e._v(" below illustrates a compact representation of cosigt workflow:")]),e._v(" "),t("p",[t("a",{attrs:{href:"./rulegraph.png"}},[t("img",{staticStyle:{display:"block",margin:"0 auto"},attrs:{src:a(364),width:"650"}})])]),e._v(" "),t("p",[e._v("This section outlines the core steps and logic behind the cosigt pipeline, which assigns structural haplotypes to sequenced samples by combining pangenome graph construction with cosine similarity-based classification. For each sample and region of interest, cosigt identifies the haplotype pair—selected from a given set of assemblies—that best explains the structural composition of that region.")]),e._v(" "),t("ol",[t("li",[t("a",{attrs:{href:"#graph-construction"}},[e._v("Graph Construction")]),e._v(": builds a pangenome graph from haplotype blocks using pggb, enabling variant representation across samples.")]),e._v(" "),t("li",[t("a",{attrs:{href:"#path-specific-node-coverage"}},[e._v("Path Coverage Analysis")]),e._v(": calculates node traversal patterns for each haplotype, creating depth matrices that capture sequence variations.")]),e._v(" "),t("li",[t("a",{attrs:{href:"#sample-specific-node-coverage"}},[e._v("Sample Projection")]),e._v(": maps short-read data to the graph space, generating sample-specific coverage vectors.")]),e._v(" "),t("li",[t("a",{attrs:{href:"#haplotype-deconvolution"}},[e._v("Similarity Matching")]),e._v(": comparse sample vectors against all possible haplotype pairs using cosine similarity to identify optimal genotype matches.")])]),e._v(" "),t("h2",{attrs:{id:"haplotypes-alignment"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#haplotypes-alignment"}},[e._v("#")]),e._v(" Haplotypes alignment")]),e._v(" "),t("p",[e._v("The pipeline begins by aligning the assembled haplotypes (queries) to their corresponding reference genome (target) using "),t("a",{attrs:{href:"https://github.com/lh3/minimap2",target:"_blank",rel:"noopener noreferrer"}},[e._v("minimap2"),t("OutboundLink")],1),e._v(". We use minimap2 with the "),t("code",[e._v("asm20")]),e._v(" preset, as it is specifically optimized for assembly-to-reference alignment and permits continuous alignment across segments when the sequence divergence do not exceed 20%, even within complex regions.")]),e._v(" "),t("h2",{attrs:{id:"target-region-liftover"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#target-region-liftover"}},[e._v("#")]),e._v(" Target region liftover")]),e._v(" "),t("p",[e._v("Following the "),t("a",{attrs:{href:"#haplotypes-alignment"}},[e._v("initial alignment")]),e._v(", the workflow leverages an implicit pangenome graph model - implemented in the "),t("a",{attrs:{href:"https://github.com/pangenome/impg",target:"_blank",rel:"noopener noreferrer"}},[e._v("impg repository"),t("OutboundLink")],1),e._v(" - to lift over coordinates of regions of interest from the target sequence to the queries. This step allows us to identify homologous "),t("em",[e._v("loci")]),e._v(" across all haplotypes that map to a specified target region. The alignment coordinates are subsequently filtered and extended to ensure comprehensive coverage of the region of interest.")]),e._v(" "),t("h2",{attrs:{id:"graph-construction"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#graph-construction"}},[e._v("#")]),e._v(" Graph construction")]),e._v(" "),t("p",[e._v("With the coordinates of the target regions "),t("a",{attrs:{href:"#target-region-liftover"}},[e._v("established")]),e._v(", the pipeline extracts the corresponding sequences from both the target and the queries, then uses the pangenome graph builder "),t("a",{attrs:{href:"https://github.com/pangenome/pggb",target:"_blank",rel:"noopener noreferrer"}},[e._v("pggb"),t("OutboundLink")],1),e._v(" to construct a local pangenome graph. In "),t("a",{attrs:{href:"https://www.nature.com/articles/s41586-024-07911-1",target:"_blank",rel:"noopener noreferrer"}},[e._v("previous work"),t("OutboundLink")],1),e._v(", we found it beneficial to collapse regions with copy-number events into single regions of the graph. Therefore, the pipeline executes "),t("code",[e._v("pggb")]),e._v(" with the "),t("code",[e._v("-c")]),e._v(" parameter set to "),t("code",[e._v("2")]),e._v(" by default, which enables us to build a graph that accurately represents variation in "),t("em",[e._v("loci")]),e._v(" with high copy number variation.")]),e._v(" "),t("h2",{attrs:{id:"structural-clustering"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#structural-clustering"}},[e._v("#")]),e._v(" Structural clustering")]),e._v(" "),t("p",[e._v("We implemented a strategy within our pipeline to identify structural clusters in the extracted haplotypes. Using the "),t("a",{attrs:{href:"#graph-construction"}},[e._v("pggb graph")]),e._v(", we compute a "),t("a",{attrs:{href:"https://en.wikipedia.org/wiki/Jaccard_index",target:"_blank",rel:"noopener noreferrer"}},[e._v("jaccard"),t("OutboundLink")],1),e._v("-based distance matrix between all haplotype pairs using "),t("a",{attrs:{href:"https://github.com/pangenome/odgi",target:"_blank",rel:"noopener noreferrer"}},[e._v("odgi"),t("OutboundLink")],1),e._v(" "),t("code",[e._v("similarity")]),e._v(" (score for each pairs ranges between "),t("code",[e._v("0")]),e._v(" and "),t("code",[e._v("1")]),e._v(", with "),t("code",[e._v("0")]),e._v(" = identical node traversal patterns; "),t("code",[e._v("1")]),e._v(" = completely disjoint paths) and apply a clustering strategy based on "),t("a",{attrs:{href:"https://en.wikipedia.org/wiki/DBSCAN",target:"_blank",rel:"noopener noreferrer"}},[e._v("DBSCAN"),t("OutboundLink")],1),e._v(" ("),t("code",[e._v("minPoints")]),e._v(" parameter is always set to "),t("code",[e._v("1")]),e._v(", while we dinamically compute the "),t("code",[e._v("eps")]),e._v("parameter of the algorithm). This approach allows us to group haplotypes by structural similarity, providing insights into the major structural variants present in the dataset.")]),e._v(" "),t("h2",{attrs:{id:"path-specific-node-coverage"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#path-specific-node-coverage"}},[e._v("#")]),e._v(" Path-specific node coverage")]),e._v(" "),t("p",[e._v("Our workflow uses "),t("a",{attrs:{href:"https://github.com/pangenome/odgi",target:"_blank",rel:"noopener noreferrer"}},[e._v("odgi"),t("OutboundLink")],1),e._v(" "),t("code",[e._v("paths")]),e._v(" to compute the coverage of each path over the nodes in the "),t("a",{attrs:{href:"#graph-construction"}},[e._v("graph")]),e._v(":")]),e._v(" "),t("ol",[t("li",[e._v("If a path crosses a certain node just once, its coverage over that node will be "),t("code",[e._v("1")])]),e._v(" "),t("li",[e._v("If a path does not cross a certain node, its coverage over that node will be "),t("code",[e._v("0")])]),e._v(" "),t("li",[e._v("If a path loops multiple times over a certain node, its coverage over that node will be "),t("code",[e._v(">=2")])])]),e._v(" "),t("p",[e._v("The path coverage information is crucial for the subsequent "),t("a",{attrs:{href:"#haplotype-deconvolution"}},[e._v("haplotype deconvolution")]),e._v(" step.")]),e._v(" "),t("h2",{attrs:{id:"reads-to-assembly-alignment"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#reads-to-assembly-alignment"}},[e._v("#")]),e._v(" Reads-to-assembly alignment")]),e._v(" "),t("p",[e._v("For each sample, short-reads spanning regions of interest are fetched from the initial alignment to the linear reference and mapped against the corresponding assembly blocks. This mapping is performed using the "),t("a",{attrs:{href:"https://github.com/bwa-mem2/bwa-mem2",target:"_blank",rel:"noopener noreferrer"}},[e._v("bwa-mem2"),t("OutboundLink")],1),e._v(" "),t("code",[e._v("mem")]),e._v(" algorithm for modern genomes. For ancient genomes, we use "),t("a",{attrs:{href:"https://github.com/lh3/bwa",target:"_blank",rel:"noopener noreferrer"}},[e._v("bwa"),t("OutboundLink")],1),e._v(" "),t("code",[e._v("aln")]),e._v(" instead, with parameters optimized for ancient DNA as suggested in "),t("a",{attrs:{href:"https://onlinelibrary.wiley.com/doi/10.1002/ece3.8297",target:"_blank",rel:"noopener noreferrer"}},[e._v("this publication"),t("OutboundLink")],1),e._v(" ("),t("code",[e._v("bwa aln -l 1024 -n 0.01 -o 2")]),e._v("). The pipeline retains alternative alignment hits to ensure comprehensive coverage of repetitive regions.")]),e._v(" "),t("h2",{attrs:{id:"sample-specific-node-coverage"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#sample-specific-node-coverage"}},[e._v("#")]),e._v(" Sample-specific node coverage")]),e._v(" "),t("p",[e._v("The "),t("a",{attrs:{href:"#reads-to-assembly-alignment"}},[e._v("alignments")]),e._v(" generated in the previous step are projected onto the graph using "),t("a",{attrs:{href:"https://github.com/AndreaGuarracino/gfainject",target:"_blank",rel:"noopener noreferrer"}},[e._v("gfainject"),t("OutboundLink")],1),e._v(". Read coverage over the graph nodes is then calculated using "),t("a",{attrs:{href:"https://github.com/pangenome/gafpack.git",target:"_blank",rel:"noopener noreferrer"}},[e._v("gafpack"),t("OutboundLink")],1),e._v(". The pipeline incorporates the "),t("code",[e._v("--len-scale")]),e._v(" parameter to normalize coverage based on node length and the "),t("code",[e._v("--weight-queries")]),e._v(" parameter to account for multiple alignments of the same read, ensuring accurate representation of coverage in repetitive regions.")]),e._v(" "),t("h2",{attrs:{id:"haplotype-deconvolution"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#haplotype-deconvolution"}},[e._v("#")]),e._v(" Haplotype deconvolution")]),e._v(" "),t("p",[e._v("In the final step of the pipeline, the coverage vector of "),t("a",{attrs:{href:"#sample-specific-node-coverage"}},[e._v("each sample")]),e._v(" is compared to a set of pre-computed haplotype coverage vectors. These haplotype vectors are generated by pairing all "),t("a",{attrs:{href:"#path-specific-node-coverage"}},[e._v("path")]),e._v(" vectors over the graph. The comparison is performed using "),t("a",{attrs:{href:"https://en.wikipedia.org/wiki/Cosine_similarity",target:"_blank",rel:"noopener noreferrer"}},[e._v("cosine similarity"),t("OutboundLink")],1),e._v(", which measures the similarity between two vectors as their dot product divided by the product of their lengths. The haplotype pair with the highest similarity to the short-read vector is assigned as the genotype for each sample in each genomic region. For haploid regions, the same principle applies, but the sample coverage vector is compared to each individual path coverage vector rather than pairs.")]),e._v(" "),t("h2",{attrs:{id:"parallelization"}},[t("a",{staticClass:"header-anchor",attrs:{href:"#parallelization"}},[e._v("#")]),e._v(" Parallelization")]),e._v(" "),t("p",[e._v("The cosigt pipeline is designed to efficiently utilize available computational resources through extensive parallelization:")]),e._v(" "),t("ol",[t("li",[e._v("The "),t("a",{attrs:{href:"#haplotypes-alignment"}},[e._v("Assembly-to-Reference Alignment")]),e._v(" runs in parallel for each chromosome and each assembly sample. The pipeline requires assembled contigs to follow the "),t("a",{attrs:{href:"https://github.com/pangenome/PanSN-spec",target:"_blank",rel:"noopener noreferrer"}},[e._v("PanSN"),t("OutboundLink")],1),e._v(" specification ("),t("code",[e._v("sample#haplotype#contig")]),e._v("). All haplotypes sharing the same assembly sample identifier are aligned to their corresponding reference chromosome in a single process. For example, with contigs from 10 different assembly samples and regions from 2 different chromosomes, the workflow can spawn up to 20 concurrent processes during this alignment step.")]),e._v(" "),t("li",[e._v("The "),t("a",{attrs:{href:"#target-region-liftover"}},[e._v("Target Region Liftover")]),e._v(" process from target sequences to assembled haplotypes operates in parallel for each assembly sample and each region, further enhancing performance when processing diverse genomic regions.")]),e._v(" "),t("li",[e._v("The different Graph Analysis operations run in parallel by region, including:\n"),t("ul",[t("li",[t("a",{attrs:{href:"#graph-construction"}},[e._v("Graph construction from assembled contigs")])]),e._v(" "),t("li",[t("a",{attrs:{href:"#structural-clustering"}},[e._v("Structural haplotype clustering")])]),e._v(" "),t("li",[t("a",{attrs:{href:"#path-specific-node-coverage"}},[e._v("Computation of coverage along graph paths")])])])]),e._v(" "),t("li",[e._v("The Sequencing Sample Processing stages of the pipeline are parallelized by both sequencing sample and region:\n"),t("ul",[t("li",[t("a",{attrs:{href:"#reads-to-assembly-alignment"}},[e._v("Short-read alignment to assembled contigs")])]),e._v(" "),t("li",[t("a",{attrs:{href:"#sample-specific-node-coverage"}},[e._v("Projection of short-read alignments into graph space")])]),e._v(" "),t("li",[t("a",{attrs:{href:"#haplotype-deconvolution"}},[e._v("Haplotype deconvolution and genotyping of sequencing samples")])])])])]),e._v(" "),t("p",[e._v("This multi-level parallelization strategy enables efficient processing of large cohorts with complex genomic regions, maximizing throughput on high-performance computing infrastructure.")])])}),[],!1,null,null,null);t.default=o.exports}}]);